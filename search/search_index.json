{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"<p>Welcome to The Internals of Kafka Streams online book! \ud83e\udd19</p> <p>I'm Jacek Laskowski, an IT freelancer specializing in Apache Spark, Delta Lake and Apache Kafka (with brief forays into a wider data engineering space, e.g. Trino and ksqlDB, mostly during Warsaw Data Engineering meetups).</p> <p>I'm very excited to have you here and hope you will enjoy exploring the internals of Kafka Streams as much as I have.</p>  <p>Flannery O'Connor</p> <p>I write to discover what I know.</p>  \"The Internals Of\" series<p>I'm also writing other online books in the \"The Internals Of\" series. Please visit \"The Internals Of\" Online Books home page.</p>  <p>Expect text and code snippets from a variety of public sources. Attribution follows.</p> <p>Now, let's take a deep dive into Kafka Streams \ud83d\udd25</p>  <p>Last update: 2021-10-07</p>","title":"The Internals of Kafka Streams 3.0.0"},{"location":"GraphNode/","text":"<p><code>GraphNode</code> is an abstraction of graph nodes (for InternalStreamsBuilder to build a topology for StreamsBuilder).</p>","title":"GraphNode"},{"location":"GraphNode/#contract","text":"","title":"Contract"},{"location":"GraphNode/#writetotopology","text":"","title":"writeToTopology <pre><code>void writeToTopology(\n  InternalTopologyBuilder topologyBuilder,\n  Properties props)\n</code></pre> <p>Used when:</p> <ul> <li><code>InternalStreamsBuilder</code> is requested to build and optimize a topology</li> </ul>"},{"location":"GraphNode/#implementations","text":"<ul> <li>ProcessorGraphNode</li> <li>StreamToTableNode</li> <li>BaseJoinProcessorNode</li> <li>SourceGraphNode</li> <li>StreamSinkNode</li> <li>StateStoreNode</li> <li>TableProcessorNode</li> <li>BaseRepartitionNode</li> <li>StreamTableJoinNode</li> </ul>","title":"Implementations"},{"location":"InternalStreamsBuilder/","text":"","title":"InternalStreamsBuilder"},{"location":"InternalStreamsBuilder/#creating-instance","text":"<p><code>InternalStreamsBuilder</code> takes the following to be created:</p> <ul> <li> InternalTopologyBuilder  <p><code>InternalStreamsBuilder</code> is created\u00a0when:</p> <ul> <li><code>StreamsBuilder</code> is created</li> </ul>","title":"Creating Instance"},{"location":"InternalStreamsBuilder/#root-node","text":"","title":"Root Node <p><code>InternalStreamsBuilder</code> creates a root GraphNode when created.</p> <p>This root node is used to addGraphNode in the following high-level operators:</p> <ul> <li>stream</li> <li>table</li> <li>globalTable</li> <li>addStateStore</li> <li>addGlobalStore</li> </ul> <p>This root node is then used to build and optimize a topology (for StreamsBuilder).</p>"},{"location":"InternalStreamsBuilder/#buildandoptimizetopology","text":"","title":"buildAndOptimizeTopology <pre><code>void buildAndOptimizeTopology(\n  Properties props)\n</code></pre> <p><code>buildAndOptimizeTopology</code>...FIXME</p> <p><code>buildAndOptimizeTopology</code>\u00a0is used when:</p> <ul> <li><code>StreamsBuilder</code> is requested to build a topology</li> </ul>"},{"location":"InternalStreamsBuilder/#mergeduplicatesourcenodes","text":"","title":"mergeDuplicateSourceNodes <pre><code>void mergeDuplicateSourceNodes()\n</code></pre> <p><code>mergeDuplicateSourceNodes</code>...FIXME</p>"},{"location":"InternalStreamsBuilder/#adding-statestore-to-topology","text":"","title":"Adding StateStore to Topology <pre><code>void addStateStore(\n  StoreBuilder&lt;?&gt; builder)\n</code></pre> <p><code>addStateStore</code> adds a new StateStoreNode to the root node.</p> <p><code>addStateStore</code> is used when:</p> <ul> <li><code>StreamsBuilder</code> is requested to addStateStore</li> <li><code>KTableImpl</code> is requested to <code>doJoinOnForeignKey</code></li> </ul>"},{"location":"KafkaClientSupplier/","text":"<p><code>KafkaClientSupplier</code> is...FIXME</p>","title":"KafkaClientSupplier"},{"location":"KafkaStreams/","text":"<p><code>KafkaStreams</code> is the execution environment of a Kafka Streams application.</p> <p><code>KafkaStreams</code> is a Kafka client for continuous stream processing (on input coming from one or more input topics and sending output to zero, one, or more output topics).</p>","title":"KafkaStreams"},{"location":"KafkaStreams/#creating-instance","text":"<p><code>KafkaStreams</code> takes the following to be created:</p> <ul> <li> InternalTopologyBuilder (or Topology) <li> StreamsConfig <li> KafkaClientSupplier (default: <code>DefaultKafkaClientSupplier</code>) <li> <code>Time</code>  <p>When created, <code>KafkaStreams</code> requests the given InternalTopologyBuilder to rewriteTopology followed by building a task and global task topologies.</p> <p><code>KafkaStreams</code> then...FIXME</p>","title":"Creating Instance"},{"location":"KafkaStreams/#defaultstreamsuncaughtexceptionhandler","text":"","title":"defaultStreamsUncaughtExceptionHandler <pre><code>void defaultStreamsUncaughtExceptionHandler(\n  Throwable throwable)\n</code></pre> <p><code>defaultStreamsUncaughtExceptionHandler</code>...FIXME</p>"},{"location":"KafkaStreams/#task-topology","text":"","title":"Task Topology <p><code>KafkaStreams</code> requests the InternalTopologyBuilder to build a task topology when created.</p> <p>The ProcessorTopology can have persistent local stores.</p>"},{"location":"KafkaStreams/#global-task-topology","text":"","title":"Global Task Topology <p>When created <code>KafkaStreams</code> requests the InternalTopologyBuilder to build a global task topology.</p>"},{"location":"KafkaStreams/#streamthreads","text":"","title":"StreamThreads <p><code>KafkaStreams</code> manages StreamThreads in a <code>threads</code> internal registry.</p> <p>The <code>threads</code> collection starts empty when <code>KafkaStreams</code> is created.</p> <p><code>KafkaStreams</code> adds a new <code>StreamThread</code> when requested to createAndAddStreamThread.</p> <p>A <code>StreamThread</code> is removed when <code>KafkaStreams</code> is requested for the following:</p> <ul> <li>defaultStreamsUncaughtExceptionHandler</li> <li>addStreamThread</li> <li>removeStreamThread</li> <li>getNumLiveStreamThreads</li> <li>getNextThreadIndex</li> </ul> <p><code>KafkaStreams</code> uses processStreamThread to work with the <code>StreamThread</code>s.</p>"},{"location":"KafkaStreams/#processstreamthread","text":"","title":"processStreamThread <pre><code>void processStreamThread(\n  java.util.function.Consumer&lt;StreamThread&gt; consumer)\n</code></pre> <p><code>processStreamThread</code>...FIXME</p>"},{"location":"KafkaStreams/#getnumlivestreamthreads","text":"","title":"getNumLiveStreamThreads <pre><code>int getNumLiveStreamThreads()\n</code></pre> <p><code>getNumLiveStreamThreads</code>...FIXME</p>"},{"location":"KafkaStreams/#globalstreamthread","text":"","title":"GlobalStreamThread <p><code>KafkaStreams</code> can use a GlobalStreamThread if...FIXME</p>"},{"location":"KafkaStreams/#starting-streams-client","text":"","title":"Starting Streams Client <pre><code>void start()\n</code></pre> <p><code>start</code> attempts to enter <code>REBALANCING</code> state and, if successful, prints out the following INFO message to the logs:</p> <pre><code>State transition from [oldState] to REBALANCING\n</code></pre> <p><code>start</code> prints out the following DEBUG message to the logs:</p> <pre><code>Starting Streams client\n</code></pre> <p><code>start</code> requests the GlobalStreamThread to start (if defined).</p> <p><code>start</code> requests all the StreamThreads to start.</p> <p><code>start</code>...FIXME</p>"},{"location":"KafkaStreams/#setuncaughtexceptionhandler","text":"","title":"setUncaughtExceptionHandler <pre><code>void setUncaughtExceptionHandler(\n  StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler)\n</code></pre> <p><code>setUncaughtExceptionHandler</code>...FIXME</p> <p><code>setUncaughtExceptionHandler</code>\u00a0is part of the public API.</p>"},{"location":"KafkaStreams/#handlestreamsuncaughtexception","text":"","title":"handleStreamsUncaughtException <pre><code>void handleStreamsUncaughtException(\n  Throwable throwable,\n  StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler)\n</code></pre> <p><code>handleStreamsUncaughtException</code>...FIXME</p> <p><code>handleStreamsUncaughtException</code>\u00a0is used when:</p> <ul> <li><code>KafkaStreams</code> is requested to setUncaughtExceptionHandler and defaultStreamsUncaughtExceptionHandler</li> </ul>"},{"location":"KafkaStreams/#replacestreamthread","text":"","title":"replaceStreamThread <pre><code>void replaceStreamThread(\n  Throwable throwable)\n</code></pre> <p><code>replaceStreamThread</code>...FIXME</p>"},{"location":"KafkaStreams/#addstreamthread","text":"","title":"addStreamThread <pre><code>Optional&lt;String&gt; addStreamThread()\n</code></pre> <p><code>addStreamThread</code>...FIXME</p> <p><code>addStreamThread</code> is part of the public API.</p>"},{"location":"KafkaStreams/#createandaddstreamthread","text":"","title":"createAndAddStreamThread <pre><code>StreamThread createAndAddStreamThread(\n  long cacheSizePerThread,\n  int threadIdx)\n</code></pre> <p><code>createAndAddStreamThread</code> creates a StreamThread and requests it to setStateListener with the StreamStateListener.</p> <p><code>createAndAddStreamThread</code> registers the <code>StreamThread</code> (in the threads and threadState internal registries).</p> <p><code>createAndAddStreamThread</code> requests the QueryableStoreProvider to addStoreProviderForThread (with the name of the <code>StreamThread</code> and a new <code>StreamThreadStateStoreProvider</code>).</p> <p><code>createAndAddStreamThread</code>\u00a0is used when:</p> <ul> <li><code>KafkaStreams</code> is created and requested to addStreamThread</li> </ul>"},{"location":"KafkaStreams/#logging","text":"","title":"Logging <p>Enable <code>ALL</code> logging level for <code>org.apache.kafka.streams.KafkaStreams</code> logger to see what happens inside.</p> <p>Add the following line to <code>log4j.properties</code>:</p> <pre><code>log4j.logger.org.apache.kafka.streams.KafkaStreams=ALL\n</code></pre> <p>Refer to Logging.</p>"},{"location":"StateStoreNode/","text":"<p><code>StateStoreNode</code> is a GraphNode.</p>","title":"StateStoreNode"},{"location":"StateStoreNode/#creating-instance","text":"<p><code>StateStoreNode</code> takes the following to be created:</p> <ul> <li> StoreBuilder  <p><code>StateStoreNode</code> is created\u00a0when:</p> <ul> <li><code>InternalStreamsBuilder</code> is requested to add a StoreBuilder</li> </ul>","title":"Creating Instance"},{"location":"StateStoreNode/#writetotopology","text":"","title":"writeToTopology <pre><code>void writeToTopology(\n  InternalTopologyBuilder topologyBuilder,\n  Properties props)\n</code></pre> <p><code>writeToTopology</code> merely requests the given InternalTopologyBuilder to add the storeBuilder.</p> <p><code>writeToTopology</code>\u00a0is part of the GraphNode abstraction.</p>"},{"location":"StreamsBuilder/","text":"<p><code>StreamsBuilder</code> provides the entry point to the High-Level Kafka Streams DSL to define and build a stream processing topology.</p>","title":"StreamsBuilder"},{"location":"StreamsBuilder/#creating-instance","text":"<p><code>StreamsBuilder</code> takes no arguments to be created.</p> <p>While being created, <code>StreamsBuilder</code> creates a Topology that in turn is requested for an InternalTopologyBuilder. In the end, <code>StreamsBuilder</code> creates an InternalStreamsBuilder.</p>","title":"Creating Instance"},{"location":"StreamsBuilder/#topology","text":"","title":"Topology <p><code>StreamsBuilder</code> creates a Topology when created.</p> <p><code>StreamsBuilder</code> uses the <code>Topology</code> to create an InternalTopologyBuilder.</p> <p>The <code>Topology</code> is then optimized and returned when <code>StreamsBuilder</code> is requested to build a topology.</p>"},{"location":"StreamsBuilder/#building-and-optimizing-topology","text":"","title":"Building and Optimizing Topology <pre><code>Topology build() // (1)\nTopology build(\n  Properties props)\n</code></pre> <ol> <li>Uses undefined properties (<code>null</code>)</li> </ol> <p><code>build</code> requests the InternalStreamsBuilder to build and optimize a topology. In the end, <code>build</code> returns the Topology.</p> <p><code>build</code> is part of the public API.</p>"},{"location":"StreamsConfig/","text":"","title":"StreamsConfig"},{"location":"StreamsConfig/#applicationid","text":"","title":"application.id"},{"location":"StreamsConfig/#cachemaxbytesbuffering","text":"","title":"cache.max.bytes.buffering"},{"location":"StreamsConfig/#pollms","text":"","title":"poll.ms <p>Time (in millis) to block waiting for input</p> <p>Default: <code>100L</code></p> <p>Used when:</p> <ul> <li><code>GlobalStateManagerImpl</code> is created</li> <li><code>GlobalStreamThread</code> is requested to initialize</li> <li><code>StoreChangelogReader</code> is created</li> <li><code>StreamThread</code> is created</li> </ul>"},{"location":"StreamsConfig/#tasktimeoutms","text":"","title":"task.timeout.ms"},{"location":"StreamsPartitionAssignor/","text":"<p><code>StreamsPartitionAssignor</code> is...FIXME</p>","title":"StreamsPartitionAssignor"},{"location":"Topology/","text":"<p><code>Topology</code> is a logical representation of a ProcessorTopology.</p> <p><code>Topology</code> is a facade to InternalTopologyBuilder (with all methods delegating to it).</p>","title":"Topology"},{"location":"Topology/#creating-instance","text":"<p><code>Topology</code> takes no arguments to be created.</p> <p><code>Topology</code> is a part of the public API of Kafka Streams and can be created directly or indirectly for StreamsBuilder.</p>","title":"Creating Instance"},{"location":"Topology/#internaltopologybuilder","text":"","title":"InternalTopologyBuilder <p><code>Topology</code> creates an InternalTopologyBuilder when created.</p>"},{"location":"Topology/#addglobalstore","text":"","title":"addGlobalStore <pre><code>&lt;KIn, VIn&gt; Topology addGlobalStore(\n  StoreBuilder&lt;?&gt; storeBuilder,\n  String sourceName,\n  Deserializer&lt;KIn&gt; keyDeserializer,\n  Deserializer&lt;VIn&gt; valueDeserializer,\n  String topic,\n  String processorName,\n  ProcessorSupplier&lt;KIn, VIn, Void, Void&gt; stateUpdateSupplier) // (1)\n&lt;KIn, VIn&gt; Topology addGlobalStore(\n  StoreBuilder&lt;?&gt; storeBuilder,\n  String sourceName,\n  TimestampExtractor timestampExtractor,\n  Deserializer&lt;KIn&gt; keyDeserializer,\n  Deserializer&lt;VIn&gt; valueDeserializer,\n  String topic,\n  String processorName,\n  ProcessorSupplier&lt;KIn, VIn, Void, Void&gt; stateUpdateSupplier)\n</code></pre> <ol> <li>Uses no TimestampExtractor</li> </ol> <p><code>addGlobalStore</code> requests the InternalTopologyBuilder to add a global store.</p>"},{"location":"Topology/#demo","text":"","title":"Demo <pre><code>import org.apache.kafka.streams.Topology\nval topology = new Topology\n</code></pre>"},{"location":"TopologyTestDriver/","text":"<p><code>TopologyTestDriver</code> is...FIXME</p>","title":"TopologyTestDriver"},{"location":"global-stores/","text":"<p>StreamsBuilder.addGlobalStore adds a global StateStore to a topology.</p> <p>Such a <code>StateStore</code> sources its data from all partitions of the provided input topic. This store uses the source topic as changelog (and during restore will insert records directly from the source).</p> <p>Global stores should not be added to <code>Processor</code>, <code>Transformer</code>, or <code>ValueTransformer</code> (unlike regular stores). They have read-only access to all global stores by default.</p> <p>There will be exactly one instance of this <code>StateStore</code> per Kafka Streams instance.</p> <p>A SourceNode will be added to consume the data arriving from the partitions of the input topic.</p>","title":"Global Stores"},{"location":"logging/","text":"","title":"Logging"},{"location":"logging/#log4jproperties","text":"","title":"log4j.properties <p>Use the following <code>log4j.properties</code> in <code>src/main/resources</code> in your Kafka Streams application's project.</p> <pre><code>log4j.rootLogger=INFO, stdout\nlog4j.appender.stdout=org.apache.log4j.ConsoleAppender\nlog4j.appender.stdout.target=System.out\nlog4j.appender.stdout.layout=org.apache.log4j.PatternLayout\nlog4j.appender.stdout.layout.ConversionPattern=[%d] %p %m (%c)%n\n\nlog4j.logger.org.apache.kafka.streams.processor.internals.StreamThread=ALL\n</code></pre>"},{"location":"logging/#slf4j","text":"","title":"SLF4J <p>Kafka Streams uses Simple Logging Facade for Java (SLF4J) for logging.</p> <p>Use <code>slf4j-api</code> and <code>slf4j-log4j12</code> library dependencies in a Kafka Streams application (in <code>build.sbt</code>) for logging.</p> <pre><code>val slf4jVersion = \"2.0.0-alpha5\"\nlibraryDependencies += \"org.slf4j\" % \"slf4j-api\" % slf4jVersion\nlibraryDependencies += \"org.slf4j\" % \"slf4j-log4j12\" % slf4jVersion\n</code></pre>"},{"location":"overview/","text":"<p>Kafka Streams is a library for developing applications for processing records from topics in Apache Kafka.</p>","title":"Kafka Streams\u2009\u2014\u2009Stream Processing Library on Apache Kafka"},{"location":"scala/","text":"<p>Scala API for Kafka Streams is...FIXME</p>","title":"Scala API for Kafka Streams"},{"location":"demo/developing-kafka-streams-application/","text":"","title":"Demo: Developing Kafka Streams Application"},{"location":"demo/developing-kafka-streams-application/#build-topology-using-streamsbuilder","text":"","title":"Build Topology using StreamsBuilder <p>A Kafka Streams application requires a Topology that can be created directly or described (and built) indirectly using StreamsBuilder.</p> <pre><code>import org.apache.kafka.streams.scala.StreamsBuilder\nval streamBuilder = new StreamsBuilder\n</code></pre> <pre><code>import org.apache.kafka.streams.scala.ImplicitConversions._\nimport org.apache.kafka.streams.scala.serialization.Serdes._\n</code></pre> <pre><code>val records = streamBuilder.stream[String, String](topic = \"streams-demo-input\")\nrecords.to(topic = \"streams-demo-output\")\n</code></pre> <pre><code>import org.apache.kafka.streams.Topology\nval topology = streamBuilder.build()\n</code></pre> <p>A topology can be described.</p> <pre><code>println(topology.describe)\n</code></pre> <pre><code>Topologies:\n   Sub-topology: 0\n    Source: KSTREAM-SOURCE-0000000000 (topics: [streams-demo-input])\n      --&gt; KSTREAM-SINK-0000000001\n    Sink: KSTREAM-SINK-0000000001 (topic: streams-demo-output)\n      &lt;-- KSTREAM-SOURCE-0000000000\n</code></pre>"},{"location":"demo/developing-kafka-streams-application/#create-kafka-topics","text":"","title":"Create Kafka Topics <p>Kafka Streams requires that all input topics are available before it can be started (or <code>MissingSourceTopicException</code> is thrown).</p> <pre><code>./bin/kafka-topics.sh \\\n  --bootstrap-server :9092 \\\n  --create \\\n  --topic streams-demo-input \\\n  --partitions 1 \\\n  --replication-factor 1\n</code></pre> <pre><code>./bin/kafka-topics.sh \\\n  --bootstrap-server :9092 \\\n  --create \\\n  --topic streams-demo-output \\\n  --partitions 1 \\\n  --replication-factor 1\n</code></pre>"},{"location":"demo/developing-kafka-streams-application/#streamsconfig","text":"","title":"StreamsConfig <p>An execution environment of a Kafka Streams application is configured using StreamsConfig.</p> <pre><code>import org.apache.kafka.streams.StreamsConfig\nimport scala.jdk.CollectionConverters._\n// Only required configuration properties\n// And one more for demo purposes to slow processing to 15 secs\n// import java.util.concurrent.TimeUnit\nimport scala.concurrent.duration._\nval props = Map(\n  StreamsConfig.APPLICATION_ID_CONFIG -&gt; \"kafka-streams-demo\",\n  StreamsConfig.BOOTSTRAP_SERVERS_CONFIG -&gt; \":9092\",\n  StreamsConfig.POLL_MS_CONFIG -&gt; 15.seconds.toMillis).asJava\nval config = new StreamsConfig(props)\n</code></pre>"},{"location":"demo/developing-kafka-streams-application/#kafkastreams","text":"","title":"KafkaStreams <p>The execution environment of a Kafka Stream application is KafkaStreams.</p> <pre><code>import org.apache.kafka.streams.KafkaStreams\nval streams = new KafkaStreams(topology, config)\n</code></pre> <p>Eventually, <code>KafkaStreams</code> should be started for the stream processing to be executed.</p> <pre><code>streams.start\n</code></pre>"},{"location":"demo/developing-kafka-streams-application/#kcat","text":"","title":"kcat <pre><code>kcat -P -b localhost -t streams-demo-input\n</code></pre> <pre><code>kcat -C -b localhost -t streams-demo-output\n</code></pre>"},{"location":"kstream/","text":"<p>Kafka Streams DSL (KStream DSL) is a high-level API for developers to define topologies in Kafka Streams.</p> <p>The entry point to the KStream DSL is StreamsBuilder.</p> <p>Main abstractions (for Kafka Streams developers):</p> <ul> <li>Consumed</li> <li>GlobalKTable</li> <li>KStream</li> <li>KTable</li> <li>Materialized</li> <li>Produced</li> <li>others</li> </ul>","title":"High-Level Kafka Streams DSL"},{"location":"kstream/Consumed/","text":"<p><code>Consumed&lt;K, V&gt;</code> describes how to consume records in a topology in the High-Level KStream DSL for the following StreamsBuilder operators:</p> <ul> <li>StreamsBuilder.stream</li> <li>StreamsBuilder.table</li> <li>StreamsBuilder.globalTable</li> <li>StreamsBuilder.addGlobalStore</li> </ul> <p><code>Consumed&lt;K, V&gt;</code> is a NamedOperation.</p>","title":"Consumed \u2014 Metadata for Consuming Records"},{"location":"kstream/Consumed/#demo","text":"<pre><code>import org.apache.kafka.common.serialization.Serdes\nimport org.apache.kafka.streams.kstream.Consumed\nval consumed = Consumed.`with`(Serdes.Long, Serdes.String)\n</code></pre> <pre><code>scala&gt; :type consumed\norg.apache.kafka.streams.kstream.Consumed[Long,String]\n</code></pre>","title":"Demo"},{"location":"kstream/Consumed/#creating-instance","text":"<p><code>Consumed</code> takes the following to be created:</p> <ul> <li> <code>Serde&lt;K&gt;</code> of keys (Apache Kafka) <li> <code>Serde&lt;V&gt;</code> of values (Apache Kafka) <li> <code>TimestampExtractor</code> <li> Reset Policy (<code>Topology.AutoOffsetReset</code>) <li> Processor Name  <p><code>Consumed</code> is created\u00a0using the factories.</p>","title":"Creating Instance"},{"location":"kstream/Consumed/#creating-consumed","text":"","title":"Creating Consumed"},{"location":"kstream/Consumed/#as","text":"","title":"as <pre><code>Consumed&lt;K, V&gt; as(\n  String processorName)\n</code></pre>"},{"location":"kstream/Consumed/#with","text":"","title":"with <pre><code>Consumed&lt;K, V&gt; with(\n  Serde&lt;K&gt; keySerde,\n  Serde&lt;V&gt; valueSerde)\nConsumed&lt;K, V&gt; with(\n  Serde&lt;K&gt; keySerde,\n  Serde&lt;V&gt; valueSerde,\n  TimestampExtractor timestampExtractor,\n  Topology.AutoOffsetReset resetPolicy)\nConsumed&lt;K, V&gt; with(\n  TimestampExtractor timestampExtractor)\nConsumed&lt;K, V&gt; with(\n  Topology.AutoOffsetReset resetPolicy)\n</code></pre>"},{"location":"kstream/Consumed/#scala-api","text":"","title":"Scala API <p>Scala API for Kafka Streams makes the optional <code>Consumed</code> metadata an implicit parameter in the StreamsBuilder API.</p> <p>Moreover, <code>ImplicitConversions</code> object defines <code>consumedFromSerde</code> implicit method that creates a <code>Consumed</code> instance with the key and value <code>Serde</code> objects available in implicit scope.</p> <p>And the last but not least, Scala API for Kafka Streams defines <code>Consumed</code> object with <code>with</code> factory methods that use implicit key and value <code>Serde</code> objects.</p>"},{"location":"kstream/GlobalKTable/","text":"<p><code>GlobalKTable</code> is...FIXME</p>","title":"GlobalKTable"},{"location":"kstream/KStream/","text":"<p><code>KStream</code> is...FIXME</p>","title":"KStream"},{"location":"kstream/KTable/","text":"<p><code>KTable</code> is...FIXME</p>","title":"KTable"},{"location":"kstream/Materialized/","text":"<p><code>Materialized</code> is...FIXME</p>","title":"Materialized"},{"location":"kstream/NamedOperation/","text":"<p><code>NamedOperation</code> is an abstraction of metadata with the name of the associated processors (and in turn the names of operations, internal topics and stores).</p>","title":"NamedOperation"},{"location":"kstream/NamedOperation/#contract","text":"","title":"Contract"},{"location":"kstream/NamedOperation/#withname","text":"","title":"withName <pre><code>T withName(\n  String name)\n</code></pre> <p>Processor name</p>"},{"location":"kstream/NamedOperation/#implementations","text":"<ul> <li>Branched</li> <li>Consumed</li> <li>Grouped</li> <li>Joined</li> <li>Named</li> <li>Printed</li> <li>Produced</li> <li>Repartitioned</li> <li>StreamJoined</li> <li>Suppressed</li> </ul>","title":"Implementations"},{"location":"kstream/Produced/","text":"<p><code>Produced&lt;K, V&gt;</code> describes how to produce records in a topology in the High-Level KStream DSL for the following high-level operators:</p> <ul> <li>KStream.to</li> </ul> <p><code>Produced&lt;K, V&gt;</code> is a NamedOperation.</p>","title":"Produced \u2014 Metadata for Producing Records"},{"location":"kstream/Produced/#demo","text":"<pre><code>import org.apache.kafka.common.serialization.Serdes\nimport org.apache.kafka.streams.kstream.Produced\nval produced = Produced.`with`(Serdes.Long, Serdes.String)\n</code></pre> <pre><code>scala&gt; :type produced\norg.apache.kafka.streams.kstream.Produced[Long,String]\n</code></pre>","title":"Demo"},{"location":"kstream/Produced/#creating-instance","text":"<p><code>Produced</code> takes the following to be created:</p> <ul> <li> <code>Serde&lt;K&gt;</code> of keys (Apache Kafka) <li> <code>Serde&lt;V&gt;</code> of values (Apache Kafka) <li> <code>StreamPartitioner&lt;? super K, ? super V&gt;</code> <li> Processor Name  <p><code>Produced</code> is created\u00a0using the factories.</p>","title":"Creating Instance"},{"location":"kstream/Produced/#creating-consumed","text":"","title":"Creating Consumed"},{"location":"kstream/Produced/#as","text":"","title":"as <pre><code>Produced&lt;K, V&gt; as(\n  String processorName)\n</code></pre>"},{"location":"kstream/Produced/#with","text":"","title":"with <pre><code>Produced&lt;K, V&gt; with(\n  Serde&lt;K&gt; keySerde,\n  Serde&lt;V&gt; valueSerde)\nProduced&lt;K, V&gt; with(\n  Serde&lt;K&gt; keySerde,\n  Serde&lt;V&gt; valueSerde,\n  StreamPartitioner&lt;? super K, ? super V&gt; partitioner)\n</code></pre>"},{"location":"kstream/Produced/#keyserde","text":"","title":"keySerde <pre><code>Produced&lt;K, V&gt; keySerde(\n  Serde&lt;K&gt; keySerde)\n</code></pre>"},{"location":"kstream/Produced/#valueserde","text":"","title":"valueSerde <pre><code>Produced&lt;K, V&gt; valueSerde(\n  Serde&lt;V&gt; valueSerde)\n</code></pre>"},{"location":"kstream/Produced/#streampartitioner","text":"","title":"streamPartitioner <pre><code>Produced&lt;K, V&gt; streamPartitioner(\n  StreamPartitioner&lt;? super K, ? super V&gt; partitioner)\n</code></pre>"},{"location":"kstream/Produced/#scala-api","text":"","title":"Scala API <p>Scala API for Kafka Streams makes the optional <code>Produced</code> metadata an implicit parameter in the KStream API.</p> <p>Moreover, <code>ImplicitConversions</code> object defines <code>producedFromSerde</code> implicit method that creates a <code>Produced</code> instance with the key and value <code>Serde</code> objects available in implicit scope.</p> <p>And the last but not least, Scala API for Kafka Streams defines <code>Produced</code> object with <code>with</code> factory methods that use implicit key and value <code>Serde</code> objects.</p>"},{"location":"processor/AbstractTask/","text":"<p><code>AbstractTask</code>\u00a0is a base abstraction of the Task abstraction for tasks.</p>","title":"AbstractTask"},{"location":"processor/AbstractTask/#implementations","text":"<ul> <li>StandbyTask</li> <li>StreamTask</li> </ul>","title":"Implementations"},{"location":"processor/AbstractTask/#creating-instance","text":"<p><code>AbstractTask</code> takes the following to be created:</p> <ul> <li> <code>TaskId</code> <li> ProcessorTopology <li> StateDirectory <li> ProcessorStateManager <li> Input <code>TopicPartition</code>s <li> task.timeout.ms configuration property <li> Task Type <li> <code>AbstractTask</code> Class  Abstract Class<p><code>AbstractTask</code>\u00a0is an abstract class and cannot be created directly. It is created indirectly for the concrete AbstractTasks.</p>","title":"Creating Instance"},{"location":"processor/ActiveTaskCreator/","text":"","title":"ActiveTaskCreator"},{"location":"processor/ActiveTaskCreator/#createtasks","text":"","title":"createTasks <pre><code>Collection&lt;Task&gt; createTasks(\n  Consumer&lt;byte[], byte[]&gt; consumer,\n  Map&lt;TaskId, Set&lt;TopicPartition&gt;&gt; tasksToBeCreated)\n</code></pre> <p><code>createTasks</code>...FIXME</p> <p><code>createTasks</code>\u00a0is used when:</p> <ul> <li><code>Tasks</code> is requested to createTasks</li> </ul>"},{"location":"processor/ActiveTaskCreator/#createactivetaskfromstandby","text":"","title":"createActiveTaskFromStandby <pre><code>StreamTask createActiveTaskFromStandby(\n  StandbyTask standbyTask,\n  Set&lt;TopicPartition&gt; inputPartitions,\n  Consumer&lt;byte[], byte[]&gt; consumer)\n</code></pre> <p><code>createActiveTaskFromStandby</code>...FIXME</p> <p><code>createActiveTaskFromStandby</code>\u00a0is used when:</p> <ul> <li><code>Tasks</code> is requested to convertStandbyToActive</li> </ul>"},{"location":"processor/ActiveTaskCreator/#createactivetask","text":"","title":"createActiveTask <pre><code>StreamTask createActiveTask(\n  TaskId taskId,\n  Set&lt;TopicPartition&gt; inputPartitions,\n  Consumer&lt;byte[], byte[]&gt; consumer,\n  LogContext logContext,\n  ProcessorTopology topology,\n  ProcessorStateManager stateManager,\n  InternalProcessorContext context)\n</code></pre> <p><code>createActiveTask</code>...FIXME</p> <p><code>createActiveTask</code>\u00a0is used when:</p> <ul> <li><code>ActiveTaskCreator</code> is requested to createTasks and createActiveTaskFromStandby</li> </ul>"},{"location":"processor/GlobalStateManagerImpl/","text":"<p><code>GlobalStateManagerImpl</code> is...FIXME</p>","title":"GlobalStateManagerImpl"},{"location":"processor/GlobalStreamThread/","text":"<p><code>GlobalStreamThread</code> is...FIXME</p>","title":"GlobalStreamThread"},{"location":"processor/InternalTopologyBuilder/","text":"","title":"InternalTopologyBuilder"},{"location":"processor/InternalTopologyBuilder/#global-topics","text":"","title":"Global Topics <pre><code>Set&lt;String&gt; globalTopics\n</code></pre> <p><code>InternalTopologyBuilder</code> tracks global topics (names) in a <code>globalTopics</code> internal registry.</p> <p>A new topic name is added in addGlobalStore.</p>"},{"location":"processor/InternalTopologyBuilder/#building-processor-topology","text":"","title":"Building Processor Topology <pre><code>ProcessorTopology build(\n  Set&lt;String&gt; nodeGroup)\n</code></pre> <p>For every NodeFactory (in the nodeFactories internal registry), if the name of the factory is in the given node group if defined or simply all node factories go through, <code>build</code> does the following:</p> <ol> <li>Requests the <code>NodeFactory</code> to build a ProcessorNode (and registers it in a local registry of processors by name)</li> <li>For <code>ProcessorNodeFactory</code>s, buildProcessorNode</li> <li>For <code>SourceNodeFactory</code>s, buildSourceNode</li> <li>For <code>SinkNodeFactory</code>s, buildSinkNode</li> </ol> <p>In the end, <code>build</code> creates a new ProcessorTopology.</p> <p><code>build</code>\u00a0is used when:</p> <ul> <li><code>InternalTopologyBuilder</code> is requested to build a topology, a subtopology and a global state topology</li> </ul>"},{"location":"processor/InternalTopologyBuilder/#buildprocessornode","text":"","title":"buildProcessorNode <pre><code>void buildProcessorNode(\n  Map&lt;String, ProcessorNode&lt;?, ?, ?, ?&gt;&gt; processorMap,\n  Map&lt;String, StateStore&gt; stateStoreMap,\n  ProcessorNodeFactory&lt;?, ?, ?, ?&gt; factory,\n  ProcessorNode&lt;Object, Object, Object, Object&gt; node)\n</code></pre> <p><code>buildProcessorNode</code>...FIXME</p>"},{"location":"processor/InternalTopologyBuilder/#building-source-node","text":"","title":"Building Source Node <pre><code>void buildSourceNode(\n  Map&lt;String, SourceNode&lt;?, ?&gt;&gt; topicSourceMap,\n  Set&lt;String&gt; repartitionTopics,\n  SourceNodeFactory&lt;?, ?&gt; sourceNodeFactory,\n  SourceNode&lt;?, ?&gt; node)\n</code></pre> <p><code>buildSourceNode</code> mutates (changes) the given <code>SourceNode</code> by topic name (<code>topicSourceMap</code>) and repartition topic names (<code>repartitionTopics</code>) collections.</p>  <p>When the pattern (of the given SourceNodeFactory) is defined, <code>buildSourceNode</code> subscriptionUpdates and requests the <code>SourceNodeFactory</code> to get the topics. Otherwise, <code>buildSourceNode</code> requests the <code>SourceNodeFactory</code> for the topics.</p> <p><code>buildSourceNode</code> adds the topic to the given <code>topicSourceMap</code> collection.</p> <p>For internal topics (in internalTopicNamesWithProperties registry), <code>buildSourceNode</code> decorates the name before adding to the given <code>topicSourceMap</code> collection and adds them to the given <code>repartitionTopics</code> collection.</p>"},{"location":"processor/InternalTopologyBuilder/#buildsinknode","text":"","title":"buildSinkNode <pre><code>void buildSinkNode(\n  Map&lt;String, ProcessorNode&lt;?, ?, ?, ?&gt;&gt; processorMap,\n  Map&lt;String, SinkNode&lt;?, ?&gt;&gt; topicSinkMap,\n  Set&lt;String&gt; repartitionTopics,\n  SinkNodeFactory&lt;?, ?&gt; sinkNodeFactory,\n  SinkNode&lt;?, ?&gt; node)\n</code></pre> <p><code>buildSinkNode</code>...FIXME</p>"},{"location":"processor/InternalTopologyBuilder/#building-local-processor-topology","text":"","title":"Building (Local) Processor Topology <pre><code>ProcessorTopology buildTopology()\n</code></pre> <p><code>buildTopology</code> initializes subscription and then builds a topology (of the node groups without the global node groups).</p> <p><code>buildTopology</code>\u00a0is used when:</p> <ul> <li><code>KafkaStreams</code> is created</li> <li><code>TopologyTestDriver</code> is requested to setupTopology</li> </ul>"},{"location":"processor/InternalTopologyBuilder/#building-processor-subtopology","text":"","title":"Building Processor SubTopology <pre><code>ProcessorTopology buildSubtopology(\n  int topicGroupId)\n</code></pre> <p><code>buildSubtopology</code> takes the <code>topicGroupId</code> node group (from the nodeGroups) and builds a topology.</p> <p><code>buildSubtopology</code>\u00a0is used when:</p> <ul> <li><code>ActiveTaskCreator</code> is requested to createTasks and createActiveTaskFromStandby</li> <li><code>StandbyTaskCreator</code> is requested to createTasks and createStandbyTaskFromActive</li> </ul>"},{"location":"processor/InternalTopologyBuilder/#building-global-state-processor-topology","text":"","title":"Building Global State Processor Topology <pre><code>ProcessorTopology buildGlobalStateTopology()\n</code></pre> <p><code>buildGlobalStateTopology</code> builds a topology of the global node groups if there are any.</p> <p><code>buildGlobalStateTopology</code> assumes that the applicationId has already been set or throws a <code>NullPointerException</code>:</p> <pre><code>topology has not completed optimization\n</code></pre> <p><code>buildGlobalStateTopology</code>\u00a0is used when:</p> <ul> <li><code>KafkaStreams</code> is created</li> <li><code>TopologyTestDriver</code> is requested to setupTopology</li> </ul>"},{"location":"processor/InternalTopologyBuilder/#rewriting-topology","text":"","title":"Rewriting Topology <pre><code>InternalTopologyBuilder rewriteTopology(\n  StreamsConfig config)\n</code></pre> <p><code>rewriteTopology</code> setApplicationId to the value of application.id configuration property.</p> <p>With cache.max.bytes.buffering enabled, <code>rewriteTopology</code>...FIXME</p> <p><code>rewriteTopology</code> requests the global StoreBuilders to build StateStores.</p> <p>In the end, <code>rewriteTopology</code> saves the StreamsConfig (and returns itself).</p> <p><code>rewriteTopology</code>\u00a0is used when:</p> <ul> <li><code>KafkaStreams</code> is created</li> <li><code>TopologyTestDriver</code> is requested to setupTopology</li> </ul>"},{"location":"processor/InternalTopologyBuilder/#globalnodegroups","text":"","title":"globalNodeGroups <pre><code>Set&lt;String&gt; globalNodeGroups()\n</code></pre> <p><code>globalNodeGroups</code> collects global source nodes from all the node groups.</p> <p><code>globalNodeGroups</code>\u00a0is used when:</p> <ul> <li><code>InternalTopologyBuilder</code> is requested to build a local (excluding global state nodes) and global state topologies</li> </ul>"},{"location":"processor/InternalTopologyBuilder/#isglobalsource","text":"","title":"isGlobalSource <pre><code>boolean isGlobalSource(\n  String nodeName)\n</code></pre> <p><code>isGlobalSource</code> finds a NodeFactory (by given <code>nodeName</code>) in nodeFactories registry.</p> <p><code>isGlobalSource</code> is positive (<code>true</code>) when the <code>NodeFactory</code> is a SourceNodeFactory with one topic only that is global. Otherwise, <code>isGlobalSource</code> is negative (<code>false</code>).</p> <p><code>isGlobalSource</code>\u00a0is used when:</p> <ul> <li><code>InternalTopologyBuilder</code> is requested to globalNodeGroups, describeGlobalStore and nodeGroupContainsGlobalSourceNode</li> </ul>"},{"location":"processor/InternalTopologyBuilder/#registering-global-store","text":"","title":"Registering Global Store <pre><code>&lt;KIn, VIn&gt; void addGlobalStore(\n  StoreBuilder&lt;?&gt; storeBuilder,\n  String sourceName,\n  TimestampExtractor timestampExtractor,\n  Deserializer&lt;KIn&gt; keyDeserializer,\n  Deserializer&lt;VIn&gt; valueDeserializer,\n  String topic,\n  String processorName,\n  ProcessorSupplier&lt;KIn, VIn, Void, Void&gt; stateUpdateSupplier)\n</code></pre> <p><code>addGlobalStore</code>...FIXME</p> <p><code>addGlobalStore</code> is used when:</p> <ul> <li><code>Topology</code> is requested to addGlobalStore</li> <li><code>GlobalStoreNode</code> is requested to <code>writeToTopology</code></li> <li><code>TableSourceNode</code> is requested to <code>writeToTopology</code></li> </ul>"},{"location":"processor/InternalTopologyBuilder/#addstatestore","text":"","title":"addStateStore <pre><code>void addStateStore(\n  StoreBuilder&lt;?&gt; storeBuilder,\n  String... processorNames) // (1)\nvoid addStateStore(\n  StoreBuilder&lt;?&gt; storeBuilder,\n  boolean allowOverride,\n  String... processorNames)\n</code></pre> <ol> <li>Uses <code>allowOverride</code> flag disabled (<code>false</code>)</li> </ol> <p><code>addStateStore</code>...FIXME</p> <p><code>addStateStore</code>\u00a0is used when:</p> <ul> <li><code>Topology</code> is requested to addProcessor and addStateStore</li> <li><code>KTableKTableJoinNode</code> is requested to <code>writeToTopology</code></li> <li><code>StatefulProcessorNode</code> is requested to <code>writeToTopology</code></li> <li><code>StateStoreNode</code> is requested to <code>writeToTopology</code></li> <li><code>StreamStreamJoinNode</code> is requested to <code>writeToTopology</code></li> <li><code>StreamToTableNode</code> is requested to <code>writeToTopology</code></li> <li><code>TableProcessorNode</code> is requested to <code>writeToTopology</code></li> <li><code>TableSourceNode</code> is requested to <code>writeToTopology</code></li> </ul>"},{"location":"processor/NodeFactory/","text":"<p><code>NodeFactory</code> is...FIXME</p>","title":"NodeFactory"},{"location":"processor/ProcessorStateManager/","text":"<p><code>ProcessorStateManager</code> is...FIXME</p>","title":"ProcessorStateManager"},{"location":"processor/ProcessorTopology/","text":"","title":"ProcessorTopology"},{"location":"processor/ProcessorTopology/#creating-instance","text":"<p><code>ProcessorTopology</code> takes the following to be created:</p> <ul> <li> <code>ProcessorNode</code>s <li> <code>SourceNode</code>s by topic <li> <code>SinkNode</code> by topic <li> <code>StateStore</code>s <li> Global <code>StateStore</code>s <li> Store names by topic <li> Repartition topics  <p><code>ProcessorTopology</code> is created\u00a0when:</p> <ul> <li><code>InternalTopologyBuilder</code> is requested to build a ProcessorTopology</li> </ul>","title":"Creating Instance"},{"location":"processor/SourceNode/","text":"<p><code>SourceNode</code> is...FIXME</p>","title":"SourceNode"},{"location":"processor/SourceNodeFactory/","text":"<p><code>SourceNodeFactory</code> is...FIXME</p>","title":"SourceNodeFactory"},{"location":"processor/StandbyTask/","text":"<p><code>StandbyTask</code> is a Task (and AbstractTask).</p>","title":"StandbyTask"},{"location":"processor/StandbyTask/#creating-instance","text":"<p><code>StandbyTask</code> takes the following to be created:</p> <ul> <li> <code>TaskId</code> <li> Input <code>TopicPartition</code>s <li> ProcessorTopology <li> StreamsConfig <li> <code>StreamsMetricsImpl</code> <li> ProcessorStateManager <li> StateDirectory <li> <code>ThreadCache</code> <li> <code>InternalProcessorContext</code>  <p>When created, <code>StandbyTask</code> requests the InternalProcessorContext to <code>transitionToStandby</code> with the ThreadCache.</p> <p><code>StandbyTask</code> is created\u00a0when:</p> <ul> <li><code>StandbyTaskCreator</code> is requested to createStandbyTask</li> </ul>","title":"Creating Instance"},{"location":"processor/StandbyTask/#abstracttask","text":"","title":"AbstractTask <p><code>StandbyTask</code> is an AbstractTask.</p>"},{"location":"processor/StandbyTask/#task-type","text":"","title":"Task Type <p><code>StandbyTask</code> uses standby-task for task type.</p>"},{"location":"processor/StandbyTask/#class","text":"","title":"Class <p><code>StandbyTask</code> uses <code>StandbyTask.class</code> for clazz.</p>"},{"location":"processor/StandbyTaskCreator/","text":"","title":"StandbyTaskCreator"},{"location":"processor/StandbyTaskCreator/#creating-instance","text":"<p><code>StandbyTaskCreator</code> takes the following to be created:</p> <ul> <li> InternalTopologyBuilder <li> StreamsConfig <li> <code>StreamsMetricsImpl</code> <li> StateDirectory <li> <code>ChangelogReader</code> <li> Thread ID <li> <code>Logger</code>  <p>When created, <code>StandbyTaskCreator</code> initializes a task sensor and a ThreadCache.</p> <p><code>StandbyTaskCreator</code> is created\u00a0when:</p> <ul> <li><code>StreamThread</code> utility is used to create a StreamThread</li> </ul>","title":"Creating Instance"},{"location":"processor/StateDirectory/","text":"<p><code>StateDirectory</code> is...FIXME</p>","title":"StateDirectory"},{"location":"processor/StateStore/","text":"<p><code>StateStore</code> is...FIXME</p>","title":"StateStore"},{"location":"processor/StateStoreFactory/","text":"<p><code>StateStoreFactory</code> is a factory of StateStores.</p> <pre><code>StateStoreFactory&lt;S extends StateStore&gt;\n</code></pre> <p><code>StateStoreFactory</code> is a <code>public static class</code> of InternalTopologyBuilder.</p>","title":"StateStoreFactory"},{"location":"processor/StateStoreFactory/#creating-instance","text":"<p><code>StateStoreFactory</code> takes the following to be created:</p> <ul> <li> StoreBuilder (of <code>S</code> StateStores)  <p><code>StateStoreFactory</code> is created\u00a0when:</p> <ul> <li><code>InternalTopologyBuilder</code> is requested to addStateStore</li> </ul>","title":"Creating Instance"},{"location":"processor/StoreChangelogReader/","text":"<p><code>StoreChangelogReader</code> is...FIXME</p>","title":"StoreChangelogReader"},{"location":"processor/StreamTask/","text":"<p><code>StreamTask</code> is a concrete AbstractTask.</p>","title":"StreamTask"},{"location":"processor/StreamTask/#creating-instance","text":"<p><code>StreamTask</code> takes the following to be created:</p> <ul> <li> <code>TaskId</code> <li> Input <code>TopicPartition</code>s <li> <code>ProcessorTopology</code> <li> Main <code>Consumer&lt;byte[], byte[]&gt;</code> <li> StreamsConfig <li> <code>StreamsMetricsImpl</code> <li> <code>StateDirectory</code> <li> <code>ThreadCache</code> <li> <code>Time</code> <li> <code>ProcessorStateManager</code> <li> <code>RecordCollector</code> <li> <code>InternalProcessorContext</code> <li> <code>LogContext</code>  <p><code>StreamTask</code> is created\u00a0when:</p> <ul> <li><code>ActiveTaskCreator</code> is requested to createActiveTask</li> <li><code>TopologyTestDriver</code> is requested to <code>setupTask</code></li> </ul>","title":"Creating Instance"},{"location":"processor/StreamThread/","text":"<p><code>StreamThread</code> is a <code>Thread</code> (Java).</p>","title":"StreamThread"},{"location":"processor/StreamThread/#creating-instance","text":"<p><code>StreamThread</code> takes the following to be created:</p> <ul> <li> <code>Time</code> <li> StreamsConfig <li> <code>Admin</code> <li> Main <code>Consumer&lt;byte[], byte[]&gt;</code> <li> Restore <code>Consumer&lt;byte[], byte[]&gt;</code> <li> <code>ChangelogReader</code> <li> <code>originalReset</code> <li> TaskManager <li> <code>StreamsMetricsImpl</code> <li> <code>InternalTopologyBuilder</code> <li> Thread ID <li> <code>LogContext</code> <li> <code>assignmentErrorCode</code> <li> <code>nextProbingRebalanceMs</code> <li> Shutdown Error Hook <li> <code>java.util.function.Consumer&lt;Throwable&gt;</code> <li> <code>java.util.function.Consumer&lt;Long&gt;</code>  <p><code>StreamThread</code> is created\u00a0using create utility.</p>","title":"Creating Instance"},{"location":"processor/StreamThread/#creating-streamthread","text":"","title":"Creating StreamThread <pre><code>StreamThread create(\n  InternalTopologyBuilder builder,\n  StreamsConfig config,\n  KafkaClientSupplier clientSupplier,\n  Admin adminClient,\n  UUID processId,\n  String clientId,\n  StreamsMetricsImpl streamsMetrics,\n  Time time,\n  StreamsMetadataState streamsMetadataState,\n  long cacheSizeBytes,\n  StateDirectory stateDirectory,\n  StateRestoreListener userStateRestoreListener,\n  int threadIdx,\n  Runnable shutdownErrorHook,\n  java.util.function.Consumer&lt;Throwable&gt; streamsUncaughtExceptionHandler)\n</code></pre> <p><code>create</code> prints out the following INFO message to the logs:</p> <pre><code>Creating restore consumer client\n</code></pre> <p><code>create</code> requests the given <code>StreamsConfig</code> for the restore consumer configs (with getRestoreConsumerClientId) and requests the given KafkaClientSupplier for a restore consumer.</p> <p><code>create</code> creates a StoreChangelogReader.</p> <p><code>create</code> creates a ThreadCache.</p> <p><code>create</code> creates a ActiveTaskCreator, a StandbyTaskCreator and a TaskManager.</p> <p><code>create</code> prints out the following INFO message to the logs:</p> <pre><code>Creating consumer client\n</code></pre> <p><code>create</code>...FIXME</p> <p><code>create</code>\u00a0is used when:</p> <ul> <li><code>KafkaStreams</code> is requested to createAndAddStreamThread</li> </ul>"},{"location":"processor/StreamThread/#logging","text":"","title":"Logging <p>Enable <code>ALL</code> logging level for <code>org.apache.kafka.streams.processor.internals.StreamThread</code> logger to see what happens inside.</p> <p>Add the following line to <code>log4j.properties</code>:</p> <pre><code>log4j.logger.org.apache.kafka.streams.processor.internals.StreamThread=ALL\n</code></pre> <p>Refer to Logging.</p>"},{"location":"processor/Task/","text":"<p><code>Task</code> is an abstraction of tasks.</p>","title":"Task"},{"location":"processor/Task/#contract","text":"","title":"Contract"},{"location":"processor/Task/#addrecords","text":"","title":"addRecords <pre><code>void addRecords(\n  TopicPartition partition,\n  Iterable&lt;ConsumerRecord&lt;byte[], byte[]&gt;&gt; records)\n</code></pre> <p>Used when:</p> <ul> <li><code>TaskManager</code> is requested to addRecordsToTasks</li> <li><code>TopologyTestDriver</code> is requested to enqueueTaskRecord</li> </ul>"},{"location":"processor/Task/#changelogoffsets","text":"","title":"changelogOffsets <pre><code>Map&lt;TopicPartition, Long&gt; changelogOffsets()\n</code></pre>"},{"location":"processor/Task/#changelogpartitions","text":"","title":"changelogPartitions <pre><code>Collection&lt;TopicPartition&gt; changelogPartitions()\n</code></pre>"},{"location":"processor/Task/#cleartasktimeout","text":"","title":"clearTaskTimeout <pre><code>void clearTaskTimeout()\n</code></pre>"},{"location":"processor/Task/#closeclean","text":"","title":"closeClean <pre><code>void closeClean()\n</code></pre>"},{"location":"processor/Task/#closecleanandrecyclestate","text":"","title":"closeCleanAndRecycleState <pre><code>void closeCleanAndRecycleState()\n</code></pre>"},{"location":"processor/Task/#closedirty","text":"","title":"closeDirty <pre><code>void closeDirty()\n</code></pre>"},{"location":"processor/Task/#commitneeded","text":"","title":"commitNeeded <pre><code>boolean commitNeeded()\n</code></pre>"},{"location":"processor/Task/#committedoffsets","text":"","title":"committedOffsets <pre><code>Map&lt;TopicPartition, Long&gt; committedOffsets()\n</code></pre>"},{"location":"processor/Task/#completerestoration","text":"","title":"completeRestoration <pre><code>void completeRestoration(\n  java.util.function.Consumer&lt;Set&lt;TopicPartition&gt;&gt; offsetResetter)\n</code></pre>"},{"location":"processor/Task/#getstore","text":"","title":"getStore <pre><code>StateStore getStore(\n  String name)\n</code></pre> <p>Used when:</p> <ul> <li><code>StreamThreadStateStoreProvider</code> is requested for stores</li> </ul>"},{"location":"processor/Task/#highwatermark","text":"","title":"highWaterMark <pre><code>Map&lt;TopicPartition, Long&gt; highWaterMark()\n</code></pre>"},{"location":"processor/Task/#taskid","text":"","title":"TaskId <pre><code>TaskId id()\n</code></pre>"},{"location":"processor/Task/#initializeifneeded","text":"","title":"initializeIfNeeded <pre><code>void initializeIfNeeded()\n</code></pre>"},{"location":"processor/Task/#inputpartitions","text":"","title":"inputPartitions <pre><code>Set&lt;TopicPartition&gt; inputPartitions()\n</code></pre>"},{"location":"processor/Task/#isactive","text":"","title":"isActive <pre><code>boolean isActive()\n</code></pre>"},{"location":"processor/Task/#markchangelogascorrupted","text":"","title":"markChangelogAsCorrupted <pre><code>void markChangelogAsCorrupted(\n  Collection&lt;TopicPartition&gt; partitions)\n</code></pre>"},{"location":"processor/Task/#markchangelogascorrupted_1","text":"","title":"markChangelogAsCorrupted <pre><code>void maybeInitTaskTimeoutOrThrow(\n  long currentWallClockMs,\n  Exception cause)\n</code></pre>"},{"location":"processor/Task/#postcommit","text":"","title":"postCommit <pre><code>void postCommit(\n  boolean enforceCheckpoint)\n</code></pre>"},{"location":"processor/Task/#preparecommit","text":"","title":"prepareCommit <pre><code>Map&lt;TopicPartition, OffsetAndMetadata&gt; prepareCommit()\n</code></pre> <p>Used when:</p> <ul> <li><code>TaskManager</code> is requested to closeDirtyAndRevive, handleCloseAndRecycle, prepareCommitAndAddOffsetsToMap, closeTaskDirty, tryCloseCleanAllActiveTasks, tryCloseCleanAllStandbyTasks and commitAndFillInConsumedOffsetsAndMetadataPerTaskMap</li> <li><code>TopologyTestDriver</code> is requested to completeAllProcessableWork, advanceWallClockTime and close</li> </ul>"},{"location":"processor/Task/#resume","text":"","title":"resume <pre><code>void resume()\n</code></pre>"},{"location":"processor/Task/#revive","text":"","title":"revive <pre><code>void revive()\n</code></pre>"},{"location":"processor/Task/#state","text":"","title":"state <pre><code>State state()\n</code></pre>"},{"location":"processor/Task/#suspend","text":"","title":"suspend <pre><code>void suspend()\n</code></pre>"},{"location":"processor/Task/#timecurrentidlingstarted","text":"","title":"timeCurrentIdlingStarted <pre><code>Optional&lt;Long&gt; timeCurrentIdlingStarted()\n</code></pre>"},{"location":"processor/Task/#updateinputpartitions","text":"","title":"updateInputPartitions <pre><code>void updateInputPartitions(\n  Set&lt;TopicPartition&gt; topicPartitions,\n  Map&lt;String, List&lt;String&gt;&gt; allTopologyNodesToSourceTopics)\n</code></pre>"},{"location":"processor/Task/#implementations","text":"<ul> <li>AbstractTask</li> <li>StandbyTask</li> <li>StreamTask</li> </ul>","title":"Implementations"},{"location":"processor/TaskManager/","text":"","title":"TaskManager"},{"location":"processor/TaskManager/#creating-instance","text":"<p><code>TaskManager</code> takes the following to be created:</p> <ul> <li> <code>Time</code> <li> <code>ChangelogReader</code> <li> Process UUID <li> Log Prefix <li> <code>StreamsMetricsImpl</code> <li> ActiveTaskCreator <li> StandbyTaskCreator <li> <code>InternalTopologyBuilder</code> <li> <code>Admin</code> <li> <code>StateDirectory</code> <li> <code>StreamThread.ProcessingMode</code>  <p><code>TaskManager</code> is created\u00a0when:</p> <ul> <li><code>StreamThread</code> utility is used to create a StreamThread</li> </ul>","title":"Creating Instance"},{"location":"processor/TaskManager/#handleassignment","text":"","title":"handleAssignment <pre><code>void handleAssignment(\n  Map&lt;TaskId, Set&lt;TopicPartition&gt;&gt; activeTasks,\n  Map&lt;TaskId, Set&lt;TopicPartition&gt;&gt; standbyTasks)\n</code></pre> <p><code>handleAssignment</code>...FIXME</p> <p><code>handleAssignment</code>\u00a0is used when:</p> <ul> <li><code>StreamsPartitionAssignor</code> is requested to onAssignment</li> </ul>"},{"location":"processor/TaskManager/#handlecloseandrecycle","text":"","title":"handleCloseAndRecycle <pre><code>void handleCloseAndRecycle(\n  Set&lt;Task&gt; tasksToRecycle,\n  Set&lt;Task&gt; tasksToCloseClean,\n  Set&lt;Task&gt; tasksToCloseDirty,\n  Map&lt;TaskId, Set&lt;TopicPartition&gt;&gt; activeTasksToCreate,\n  Map&lt;TaskId, Set&lt;TopicPartition&gt;&gt; standbyTasksToCreate,\n  LinkedHashMap&lt;TaskId, RuntimeException&gt; taskCloseExceptions)\n</code></pre> <p><code>handleCloseAndRecycle</code>...FIXME</p>"},{"location":"processor/Tasks/","text":"","title":"Tasks"},{"location":"processor/Tasks/#createtasks","text":"","title":"createTasks <pre><code>void createTasks(\n  Map&lt;TaskId, Set&lt;TopicPartition&gt;&gt; activeTasksToCreate,\n  Map&lt;TaskId, Set&lt;TopicPartition&gt;&gt; standbyTasksToCreate)\n</code></pre> <p><code>createTasks</code>...FIXME</p> <p><code>createTasks</code>\u00a0is used when:</p> <ul> <li><code>TaskManager</code> is requested to handleAssignment</li> </ul>"},{"location":"processor/Tasks/#convertstandbytoactive","text":"","title":"convertStandbyToActive <pre><code>void convertStandbyToActive(\n  StandbyTask standbyTask,\n  Set&lt;TopicPartition&gt; partitions)\n</code></pre> <p><code>convertStandbyToActive</code>...FIXME</p> <p><code>convertStandbyToActive</code>\u00a0is used when:</p> <ul> <li><code>TaskManager</code> is requested to handleCloseAndRecycle</li> </ul>"},{"location":"processor/TimestampExtractor/","text":"<p><code>TimestampExtractor</code> is...FIXME</p>","title":"TimestampExtractor"},{"location":"state/AbstractStoreBuilder/","text":"<p><code>AbstractStoreBuilder</code> is...FIXME</p>","title":"AbstractStoreBuilder"},{"location":"state/InMemoryWindowBytesStoreSupplier/","text":"<p><code>InMemoryWindowBytesStoreSupplier</code> is a WindowBytesStoreSupplier.</p>","title":"InMemoryWindowBytesStoreSupplier"},{"location":"state/InMemoryWindowBytesStoreSupplier/#creating-instance","text":"<p><code>InMemoryWindowBytesStoreSupplier</code> takes the following to be created:</p> <ul> <li> Name <li> <code>retentionPeriod</code> <li> <code>windowSize</code> <li> <code>retainDuplicates</code>  <p><code>InMemoryWindowBytesStoreSupplier</code> is created\u00a0when:</p> <ul> <li><code>Stores</code> is requested for in-memory window store</li> </ul>","title":"Creating Instance"},{"location":"state/QueryableStoreProvider/","text":"<p><code>QueryableStoreProvider</code> is...FIXME</p>","title":"QueryableStoreProvider"},{"location":"state/StoreBuilder/","text":"<p><code>StoreBuilder</code> is an abstraction of builders of StateStores (with optional caching and logging).</p> <pre><code>StoreBuilder&lt;T extends StateStore&gt;\n</code></pre>","title":"StoreBuilder"},{"location":"state/StoreBuilder/#contract","text":"","title":"Contract"},{"location":"state/StoreBuilder/#building-statestore","text":"","title":"Building StateStore <pre><code>T build()\n</code></pre> <p>Used when:</p> <ul> <li><code>InternalTopologyBuilder</code> is requested to rewriteTopology (and build global state stores)</li> <li><code>StateStoreFactory</code> is requested to build a StateStore</li> </ul>"},{"location":"state/StoreBuilder/#logconfig","text":"","title":"logConfig <pre><code>Map&lt;String, String&gt; logConfig()\n</code></pre>"},{"location":"state/StoreBuilder/#loggingenabled","text":"","title":"loggingEnabled <pre><code>boolean loggingEnabled()\n</code></pre>"},{"location":"state/StoreBuilder/#name","text":"","title":"name <pre><code>String name()\n</code></pre>"},{"location":"state/StoreBuilder/#withcachingdisabled","text":"","title":"withCachingDisabled <pre><code>StoreBuilder&lt;T&gt; withCachingDisabled()\n</code></pre>"},{"location":"state/StoreBuilder/#withcachingenabled","text":"","title":"withCachingEnabled <pre><code>StoreBuilder&lt;T&gt; withCachingEnabled()\n</code></pre>"},{"location":"state/StoreBuilder/#withloggingdisabled","text":"","title":"withLoggingDisabled <pre><code>StoreBuilder&lt;T&gt; withLoggingDisabled()\n</code></pre>"},{"location":"state/StoreBuilder/#withloggingenabled","text":"","title":"withLoggingEnabled <pre><code>StoreBuilder&lt;T&gt; withLoggingEnabled(\n  Map&lt;String, String&gt; config)\n</code></pre>"},{"location":"state/StoreBuilder/#implementations","text":"<ul> <li>AbstractStoreBuilder</li> </ul>","title":"Implementations"},{"location":"state/StoreSupplier/","text":"<p><code>StoreSupplier</code> is an abstraction of suppliers of StateStores.</p>","title":"StoreSupplier"},{"location":"state/StoreSupplier/#contract","text":"","title":"Contract"},{"location":"state/StoreSupplier/#creating-statestore","text":"","title":"Creating StateStore <pre><code>T get()\n</code></pre> <p>Used when:</p> <ul> <li><code>KStreamImplJoin</code> is requested to <code>sharedOuterJoinWindowStoreBuilder</code></li> <li><code>KeyValueStoreBuilder</code> is requested to <code>build</code></li> <li><code>SessionStoreBuilder</code> is requested to <code>build</code></li> <li><code>TimeOrderedWindowStoreBuilder</code> is requested to <code>build</code></li> <li><code>TimestampedKeyValueStoreBuilder</code> is requested to <code>build</code></li> <li><code>TimestampedWindowStoreBuilder</code> is requested to <code>build</code></li> <li><code>WindowStoreBuilder</code> is requested to <code>build</code></li> </ul>"},{"location":"state/StoreSupplier/#metricsscope","text":"","title":"metricsScope <pre><code>String metricsScope()\n</code></pre>"},{"location":"state/StoreSupplier/#name","text":"","title":"name <pre><code>String name()\n</code></pre>"},{"location":"state/StoreSupplier/#implementations","text":"<ul> <li>KeyValueBytesStoreSupplier</li> <li>SessionBytesStoreSupplier</li> <li>WindowBytesStoreSupplier</li> </ul>","title":"Implementations"},{"location":"state/Stores/","text":"<p><code>Stores</code> is a factory for creating state stores in Kafka Streams.</p>","title":"Stores"},{"location":"state/Stores/#inmemorywindowstore","text":"","title":"inMemoryWindowStore <pre><code>WindowBytesStoreSupplier inMemoryWindowStore(\n  String name,\n  Duration retentionPeriod,\n  Duration windowSize,\n  boolean retainDuplicates)\n</code></pre> <p><code>inMemoryWindowStore</code>...FIXME</p> <p><code>inMemoryWindowStore</code>\u00a0is used when:</p> <ul> <li><code>KStreamImplJoin</code> is requested to <code>sharedOuterJoinWindowStoreBuilder</code> (for left outer join)</li> </ul>"},{"location":"state/StreamThreadStateStoreProvider/","text":"<p><code>StreamThreadStateStoreProvider</code> is...FIXME</p>","title":"StreamThreadStateStoreProvider"},{"location":"state/ThreadCache/","text":"<p><code>ThreadCache</code> is...FIXME</p>","title":"ThreadCache"},{"location":"state/WindowBytesStoreSupplier/","text":"<p><code>WindowBytesStoreSupplier</code>\u00a0is an extension of the StoreSupplier abstraction for state store suppliers of WindowStores (<code>WindowStore&lt;Bytes, byte[]&gt;</code>s).</p>","title":"WindowBytesStoreSupplier"},{"location":"state/WindowBytesStoreSupplier/#contract","text":"","title":"Contract"},{"location":"state/WindowBytesStoreSupplier/#retainduplicates","text":"","title":"retainDuplicates <pre><code>boolean retainDuplicates()\n</code></pre>"},{"location":"state/WindowBytesStoreSupplier/#retentionperiod","text":"","title":"retentionPeriod <pre><code>long retentionPeriod()\n</code></pre>"},{"location":"state/WindowBytesStoreSupplier/#segmentintervalms","text":"","title":"segmentIntervalMs <pre><code>long segmentIntervalMs()\n</code></pre>"},{"location":"state/WindowBytesStoreSupplier/#windowsize","text":"","title":"windowSize <pre><code>long windowSize()\n</code></pre>"},{"location":"state/WindowBytesStoreSupplier/#implementations","text":"<ul> <li>RocksDbWindowBytesStoreSupplier</li> <li>InMemoryWindowBytesStoreSupplier</li> </ul>","title":"Implementations"},{"location":"state/WindowStore/","text":"<p><code>WindowStore</code> is...FIXME</p>","title":"WindowStore"}]}